# What you will find here
This repository contains my solutions to five challenges and one final project for successfully completing the Data Engineer NanoDegree program from Udacity.

WHile the five challenges where somewhat guided and with resources from Udacity, the last 'Capstone' project is quite open-ended in its implementation. An outline, guidelines and criteria are given, but the dataset is free to choose, as well as the architecture, tools and technical solution.

In each of the folders, you will find the references and helpful links to that particular challenge in the README.md, as well as a more detailled description of the challenge / project itself.

## Top three takeaways from the program for me
- Learning broad about data engineering and deep about Modeling, Warehousing, Data Lakes
- Learning on architecture and the why of Distributed Systems for scalability and efficiency for very large datasets
- Learning or improving on my tool skills: PySpark, Postgres, Cassandra, SQL, AWS and Airflow 

# Outline of the Data Engineer Nanodegree Program from Udacity

#### Data Modeling
  - Data Modeling with Postgres (Challenge 1)
  - Data Modeling with Apache Cassandra (Challenge 2)

#### Cloud Data Warehouses 
  - Build a Data Warehouse with AWS (Challenge 3)

#### Data Lakes (Spark)
  - Build a Data Lake and work with Spark (Challenge 4)

#### Data Pipelines (Airflow)
  - Builing and maintaining Data Pipelines with Apache Airflow (Challenge 5)

#### Capstone Project (Final assesment)
  - Combine the learned concepts and tools to build an own data engineering project

Requirements: Intermediate Python & SQL

Reference for program outline: https://www.udacity.com/course/data-engineer-nanodegree--nd027


